{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(df)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m,n = data.shape          # get the shape of the data \n",
    "np.random.shuffle(data)  #because data samples werent random \n",
    "\n",
    "datatest = data[0:1000].T # transposed the data so that each column represents an example\n",
    "\n",
    "\n",
    "datatrain = data[1000 : m].T\n",
    "ytrain = datatrain[0]\n",
    "xtrain = datatrain[1:n]\n",
    "xtrain= xtrain/255\n",
    "xtrain[:,0].shape                                                                  \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameter():\n",
    "    w1 = np.random.rand(10,784)-0.5\n",
    "    b1 = np.random.rand(10 ,1)-0.5\n",
    "    w2 = np.random.rand(10,10)-0.5\n",
    "    b2 = np.random.rand(10,1)-0.5\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "def softmax(z):\n",
    "   return np.exp(z)/sum(np.exp(z))\n",
    "\n",
    "def deriv_relu(z):\n",
    "    return z>0\n",
    "\n",
    "def onehot(y):\n",
    "    onehot_y = np.zeros((y.size, y.max() +1 ))\n",
    "    onehot_y[np.arange(y.size), y] = 1\n",
    "    onehot_y = onehot_y.T\n",
    "    return onehot_y\n",
    "\n",
    "\n",
    "def forward_propagation(w1 ,b1 , w2 ,b2 , x):\n",
    "    z1= w1.dot(x) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = w2.dot(a1) +b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1 , a1 , z2 , a2 \n",
    "\n",
    "def backprop(z1 ,a1 , z2 , a2 , w2,x , y):\n",
    "    onehot_y = onehot(y)\n",
    "    dz2 = a2 -onehot_y #calculating the deravative by subtracting activation values from truth labels\n",
    "    dw2 = 1/m * dz2.dot(a1.T) #This line calculates the gradient of the weights (W2) connecting the hidden layer to the output layer.\n",
    "    db2 = 1/m * np.sum(dz2) #gradient of bias\n",
    "    dz1 = w2.T.dot(dz2) * deriv_relu(z1)# the derivative of the loss function with respect to the pre-activation values of the hidden layer\n",
    "    dw1 = 1/m * dz1.dot(x.T)#the gradient of the weights (W1) connecting the input layer to the hidden layer\n",
    "    db1 = 1/m * np.sum(dz1)#This line computes the gradient of the biases (b1) in the hidden layer. It calculates the average of the derivative of the loss.\n",
    "    return dw1 , db1 , dw2 , db2 \n",
    "\n",
    "def updatepara(w1,b1,w2,b2,dw1,db1,dw2,db2,alpha):\n",
    "    w1 = w1 - alpha*dw1\n",
    "    b1 = b1 - alpha* db1\n",
    "    w2 = w2 - alpha*dw2\n",
    "    b2 = b2 - alpha*db2\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "def get_predicts(a2):\n",
    "    return np.argmax(a2,0)\n",
    "\n",
    "def get_accuracy(predicts , y):\n",
    "    print(predicts,y)\n",
    "    return np.sum(predicts==y)/y.size\n",
    "\n",
    "\n",
    "def gradientdescent(x,y,ite,alpha):\n",
    "    w1,b1,w2,b2 = init_parameter()\n",
    "    for i in range(ite):\n",
    "        z1 ,a1, z2,a2 = forward_propagation(w1,b1,w2,b2,x)\n",
    "        dw1,db1,dw2,db2 = backprop(z1,a1,z2,a2,w2,x,y)\n",
    "        w1,b1,w2,b2 = updatepara(w1,b1,w2,b2,dw1,db1,dw2,db2,alpha)\n",
    "        if i% 10 ==0:\n",
    "            print('iteration',i)\n",
    "            print('accuracy', get_accuracy(get_predicts(a2),y))\n",
    "    return w1 , b1 , w2 ,b2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "[7 4 4 ... 0 7 8] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.082\n",
      "iteration 10\n",
      "[7 3 3 ... 3 7 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.30377777777777776\n",
      "iteration 20\n",
      "[7 5 3 ... 8 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.4677777777777778\n",
      "iteration 30\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.6434444444444445\n",
      "iteration 40\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.677\n",
      "iteration 50\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.6825555555555556\n",
      "iteration 60\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.7505555555555555\n",
      "iteration 70\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.7807777777777778\n",
      "iteration 80\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.7976666666666666\n",
      "iteration 90\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8174444444444444\n",
      "iteration 100\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8284444444444444\n",
      "iteration 110\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8378888888888889\n",
      "iteration 120\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8464444444444444\n",
      "iteration 130\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.852\n",
      "iteration 140\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8577777777777778\n",
      "iteration 150\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.862\n",
      "iteration 160\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8662222222222222\n",
      "iteration 170\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8713333333333333\n",
      "iteration 180\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8752222222222222\n",
      "iteration 190\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8778888888888889\n",
      "iteration 200\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8781111111111111\n",
      "iteration 210\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8801111111111111\n",
      "iteration 220\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8871111111111111\n",
      "iteration 230\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8911111111111111\n",
      "iteration 240\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8927777777777778\n",
      "iteration 250\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.89\n",
      "iteration 260\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8904444444444445\n",
      "iteration 270\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8957777777777778\n",
      "iteration 280\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9002222222222223\n",
      "iteration 290\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9011111111111111\n",
      "iteration 300\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8975555555555556\n",
      "iteration 310\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.8867777777777778\n",
      "iteration 320\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.905\n",
      "iteration 330\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9078888888888889\n",
      "iteration 340\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9091111111111111\n",
      "iteration 350\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9095555555555556\n",
      "iteration 360\n",
      "[1 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9065555555555556\n",
      "iteration 370\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9042222222222223\n",
      "iteration 380\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9071111111111111\n",
      "iteration 390\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9128888888888889\n",
      "iteration 400\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.914\n",
      "iteration 410\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9148888888888889\n",
      "iteration 420\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9157777777777778\n",
      "iteration 430\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.917\n",
      "iteration 440\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9174444444444444\n",
      "iteration 450\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9177777777777778\n",
      "iteration 460\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9181111111111111\n",
      "iteration 470\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9192222222222223\n",
      "iteration 480\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9201111111111111\n",
      "iteration 490\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9216666666666666\n",
      "iteration 500\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9217777777777778\n",
      "iteration 510\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9221111111111111\n",
      "iteration 520\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9227777777777778\n",
      "iteration 530\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.923\n",
      "iteration 540\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9231111111111111\n",
      "iteration 550\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9242222222222222\n",
      "iteration 560\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9245555555555556\n",
      "iteration 570\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9253333333333333\n",
      "iteration 580\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9255555555555556\n",
      "iteration 590\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9264444444444444\n",
      "iteration 600\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.927\n",
      "iteration 610\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9281111111111111\n",
      "iteration 620\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9285555555555556\n",
      "iteration 630\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9288888888888889\n",
      "iteration 640\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9293333333333333\n",
      "iteration 650\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9298888888888889\n",
      "iteration 660\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9307777777777778\n",
      "iteration 670\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9314444444444444\n",
      "iteration 680\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9321111111111111\n",
      "iteration 690\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9327777777777778\n",
      "iteration 700\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9333333333333333\n",
      "iteration 710\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.934\n",
      "iteration 720\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9345555555555556\n",
      "iteration 730\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9348888888888889\n",
      "iteration 740\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9354444444444444\n",
      "iteration 750\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9356666666666666\n",
      "iteration 760\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.936\n",
      "iteration 770\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9364444444444444\n",
      "iteration 780\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9368888888888889\n",
      "iteration 790\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9372222222222222\n",
      "iteration 800\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9373333333333334\n",
      "iteration 810\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9378888888888889\n",
      "iteration 820\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9382222222222222\n",
      "iteration 830\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9387777777777778\n",
      "iteration 840\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9393333333333334\n",
      "iteration 850\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9397777777777778\n",
      "iteration 860\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9403333333333334\n",
      "iteration 870\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9406666666666667\n",
      "iteration 880\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9407777777777778\n",
      "iteration 890\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9408888888888889\n",
      "iteration 900\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9411111111111111\n",
      "iteration 910\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9415555555555556\n",
      "iteration 920\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9421111111111111\n",
      "iteration 930\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9422222222222222\n",
      "iteration 940\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9424444444444444\n",
      "iteration 950\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9427777777777778\n",
      "iteration 960\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9433333333333334\n",
      "iteration 970\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.944\n",
      "iteration 980\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9441111111111111\n",
      "iteration 990\n",
      "[8 8 3 ... 1 8 0] [8 8 3 ... 1 8 7]\n",
      "accuracy 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "w1,b1,w2,b2 = gradientdescent(xtrain,ytrain,1000,0.47) #ther value of learning rate was decided by hit and trial and constant tweaking which resulted in this value providing upto 94% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
